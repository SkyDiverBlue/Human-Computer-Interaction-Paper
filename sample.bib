@misc{LeBlanc2011,

    author =        {LeBlanc, Brandon},
    title =         {{Beta for Kinect for Windows SDK Now Available! | Windows Experience Blog}},
    url =           {https://blogs.windows.com/windowsexperience/2011/06/16/beta-for-kinect-for-windows-sdk-now-available/},
    urldate =       {2020-05-27},
    year =          {2011}
}

@article{Pasch2009,

    abstract    = {The phenomenon of immersing oneself into virtual environments has been established widely. Yet to date (to our best knowledge) the physical dimension has been neglected in studies investigating immersion in Human-Computer Interaction (HCI). In movement-based interaction the user controls the interface via body movements, e.g. direct manipulation of screen objects via gestures or using a handheld controller as a virtual tennis racket. It has been shown that physical activity affects arousal and that movement-based controllers can facilitate engagement in the context of video games. This paper aims at identifying movement features that influence immersion. We first give a brief survey on immersion and movement-based interfaces. Then, we report results from an interview study that investigates how users experience their body movements when interacting with movement-based interfaces. Based on the interviews, we identify four movement-specific features. We recommend them as candidates for further investigation. {\textcopyright} ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2009.},
    author      = {Pasch, Marco and Bianchi-Berthouze, Nadia and {Van Dijk}, Betsy and Nijholt, Anton},
    doi         = {10.1007/978-3-642-02315-6_16},
    isbn        = {3642023142},
    issn        = {18678211},
    journal     = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering},
    keywords    = {Engagement,Entertainment,Exertion,Flow,Games,Immersion,Movement-based interaction},
    pages       = {169--180},
    title       = {{Immersion in movement-based interaction}},
    volume      = {9 LNICST},
    year        = {2009}
}

@article{Baqai2017,

    abstract        = {The use of motion controllers and cameras such as Microsoft Kinect as a gaming peripheral have increased the immersion of computer games today. Moving to using gestures instead of conventional handheld game controllers has increased the interest of players. Xbox 360, Xbox-One and the games that have been developed to be used with Kinect enable users to play using gestures, but this limits us to play our old favorite games and the new non-Kinect based games with same conventional peripherals. To overcome this limitation, we have developed a user friendly interface in MATLAB that replaces keyboard and mouse controls with our own designed gestures and enables us to play all non-Kinect based games using Kinect. For testing and demonstration purpose, we have applied the developed interface to three games which are Counter-Strike Global Offense, Candy Crush and Asphalt 8 Airborne.},
    author      = {Baqai, Attiya and Memon, Azam Rafique and Memon, Khuhed and Shah, Syed Muhammad Zaigham Abbas},
    doi         = {10.1007/s11277-016-3914-4},
    file        = {:C$\backslash$:/Users/Marine/Downloads/Baqai2017{\_}Article{\_}KinectAsAGeneralisedInterfaceF.pdf:pdf},
    isbn        = {1127701639144},
    issn        = {1572834X},
    journal     = {Wireless Personal Communications},
    keywords    = {Game interface,Gestures,Keyboard,Microsoft Kinect,Mouse},
    number      = {2},
    pages       = {617--629},
    publisher   = {Springer US},
    title       = {{Kinect as a Generalised Interface for Games and PC Control}},
    volume      = {95},
    year        = {2017}
}

@article{Andersen2012,

    abstract        = {This technical report describes our evaluation of the Kinect depth sensor by Microsoft for Computer Vision applications. The depth sensor is able to return images like an ordinary camera, but instead of color, each pixel value represents the distance to the point. As such, the sensor can be seen as a range- or 3D-camera. We have used the sensor in several different computer vision projects and this document collects our experiences with the sensor. We are only focusing on the depth sensing capabilities of the sensor since this is the real novelty of the product in relation to computer vision. The basic technique of the depth sensor is to emit an infrared light pattern (with an IR laser diode) and calculate depth from the reflection of the light at different posi- tions (using a traditional IR sensitive camera). In this report, we perform an extensive evaluation of the depth sensor and investigate issues such as 3D resolution and precision, structural noise, multi-cam setups and transient response of the sensor. The purpose is to give the reader a well-founded background to choose whether or not the Kinect sen- sor is applicable to a specific problem},
    author      = {Andersen, M R and Jensen, T and Lisouski, P and Mortensen, A K and Hansen, M K and Gregersen, T and Ahrendt, P},
    file        = {:C$\backslash$:/Users/Marine/Downloads/Technical{\_}Report{\_}ECE-TR-6-samlet.pdf:pdf},
    title       = {{Kinect Depth Sensor Evaluation for Computer Vision Applications}},
    year        = {2012}
}

@misc{Nielsen,

    abstract    = {Inconsistent gestures, invisible commands, overlooked warnings, awkward dialog confirmations. But fun to play.},
    author      = {Nielsen, Jakob},
    keywords    = {Human Computer Interaction},
    mendeley-tags = {Human Computer Interaction},
    title       = {{Kinect Gestural UI: First Impressions}},
    url         = {https://www.nngroup.com/articles/kinect-gestural-ui-first-impressions/},
    urldate     = {2020-05-27},
    year        = {2010}
}

@article{Francese2012,

    abstract    = {The recent diffusion of advanced controllers, initially designed for the home game console, has been rapidly followed by the release of proprietary or third part PC drivers and SDKs suitable for implementing new forms of 3D user interfaces based on gestures. Exploiting the devices currently available on the game market, it is now possible to enrich, with low cost motion capture, the user interaction with desktop computers by building new forms of natural interfaces and new action metaphors that add the third dimension as well as a physical extension to interaction with users. This paper presents two systems specifically designed for 3D gestural user interaction on 3D geographical maps. The proposed applications rely on two consumer technologies both capable of motion tracking: the Nintendo Wii and the Microsoft Kinect devices. The work also evaluates, in terms of subjective usability and perceived sense of Presence and Immersion, the effects on users of the two different controllers and of the 3D navigation metaphors adopted. Results are really encouraging and reveal that, users feel deeply immerse in the 3D dynamic experience, the gestural interfaces quickly bring the interaction from novice to expert style and enrich the synthetic nature of the explored environment exploiting user physicality. {\textcopyright} 2012 ACM.},
    author      = {Francese, Rita and Passero, Ignazio and Tortora, Genoveffa},
    doi         = {10.1145/2254556.2254580},
    file        = {:C$\backslash$:/Users/Marine/Downloads/2254556.2254580.pdf:pdf},
    isbn        = {9781450312875},
    journal     = {Proceedings of the Workshop on Advanced Visual Interfaces AVI},
    keywords    = {3D interfaces,Kinect,empirical evaluation,human computer interaction,motion capture,natural user interfaces,wiimote},
    pages       = {116--123},
    title       = {{Wiimote and kinect: Gestural user interfaces add a natural third dimension to HCI}},
    year        = {2012}
}

@MasterThesis{Pirttiniemi2012,

abstract = {The Kinect device opened a world of new possibilities for developers and user interface designers to explore. With Kinect, users can interact with user interfaces by using just their hands and body. A typical example of a natural user interface, or NUI, is an Xbox 360 game that uses Kinect as its only input method. The PC version is faster and more accurate than its Xbox 360 counterpart. This encouraged us to research ways and methods how we could utilize it in terms of improved usability. Unfortunately, the NUI takes us a step backwards in terms of usability, since no haptic feedback is available when interacting with it. The theory of NUI is a decades-old research field, but with the advances in technology in recent years, it has finally become a reality for the consumers. Using just your body to interact with the NUI is slow and sometimes error-prone compared to the classic mouse and keyboard interaction. Our main research question was how to speed up the interaction with NUIs and still keep it easy, accurate and nearly error-free. We chose two of the most commonly used NUI interaction types as our comparison points, and we developed nine new interaction types as our proposals. We ran usability tests of 20 participants and recorded the completion times for each of the interaction types and also the error rates. Based on the usability test results, the two-handed push button was the fastest of the interaction types, and at the same time almost error-free. The majority of the participants also chose the two-handed push button as their favorite interaction type.},
author = {Pirttiniemi, Tommi and Thesis, M Sc and Raisamo, Roope},
file = {:C$\backslash$:/Users/Marine/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pirttiniemi, Thesis, Raisamo - 2012 - Usability of natural user interface buttons using Kinect.pdf:pdf},
keywords = {Kinect,hand gestures,human-computer interaction ii,image algorithms,natural user interface,usability study},
title = {{Usability of natural user interface buttons using Kinect}},
year = {2012}
school = {University of Tampere}
}

@misc{Corden2018,
abstract = {Microsoft has finally killed Kinect, ending an experiment that began at E3 in 2009, meeting its final curtain call late in 2017 when Microsoft confirmed that Kinect production had been ended.},
author = {Corden, Jez},
booktitle = {Windows Central},
month = {jan},
title = {{Farewell, dear sweet Kinect}},
url = {https://www.windowscentral.com/ode-kinect},
urldate = {2020-05-27},
year = {2018}
}

